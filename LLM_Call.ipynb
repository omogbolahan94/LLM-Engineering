{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18715350-900a-4951-b92d-dd3fd4327a90",
   "metadata": {},
   "source": [
    "### Introduction to LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b7f45b57-55e9-4ff3-89fa-45183f870fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import requests\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "72dcec5b-b535-45f5-9594-2c5b9154a990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "1a9475fa-8f67-484b-bf03-d1f2ebc59f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd68353a-9ebc-4cb1-b941-2f9c2924fca8",
   "metadata": {},
   "source": [
    "Using ChatGPT HTTP Endpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80f49b3b-0e3a-47fb-8bc1-1ce6f6406c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'Authorization':f'Bearer {api_key}', 'Content_Type':'application/json'}\n",
    "\n",
    "payload = (\n",
    "    {'model':'gpt-5-nano', \n",
    "     'messages':[ {'role':'user', 'content': 'Hi, it is nice to meet my AI buddy'}]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e18bd9a9-c146-4c3c-bfaa-8d2c06f0485c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.post(\n",
    "    \"https://api.openai.com/v1/chat/completions\",\n",
    "    headers=headers,\n",
    "    json=payload\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57dd5c5e-2dab-4b5a-9063-7494c91f0665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'chatcmpl-D2cFN7XY0ioNDYnNbFA4QQXvGmeBb',\n",
       " 'object': 'chat.completion',\n",
       " 'created': 1769516049,\n",
       " 'model': 'gpt-5-nano-2025-08-07',\n",
       " 'choices': [{'index': 0,\n",
       "   'message': {'role': 'assistant',\n",
       "    'content': 'Nice to meet you too! I’m here to help with whatever you need—explain concepts, brainstorm ideas, write or edit, plan things, debug code, learn a new topic, or just chat.\\n\\nWhat would you like to start with? A quick interests check (what you enjoy or want to learn), a specific task, or a playful activity? If you’re not sure, I can suggest a few options:\\n- Explain a concept you’re curious about in simple terms\\n- Help draft an email or document\\n- Plan a study or workout routine\\n- Brainstorm ideas for a project or story\\n- Tell you a joke or a fun fact\\n\\nTell me what you’re hoping for, and we’ll dive in.',\n",
       "    'refusal': None,\n",
       "    'annotations': []},\n",
       "   'finish_reason': 'stop'}],\n",
       " 'usage': {'prompt_tokens': 16,\n",
       "  'completion_tokens': 540,\n",
       "  'total_tokens': 556,\n",
       "  'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0},\n",
       "  'completion_tokens_details': {'reasoning_tokens': 384,\n",
       "   'audio_tokens': 0,\n",
       "   'accepted_prediction_tokens': 0,\n",
       "   'rejected_prediction_tokens': 0}},\n",
       " 'service_tier': 'default',\n",
       " 'system_fingerprint': None}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5922e9eb-2f88-4c69-aef2-8edfaab9acad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nice to meet you too! I’m here to help with whatever you need—explain concepts, brainstorm ideas, write or edit, plan things, debug code, learn a new topic, or just chat.\\n\\nWhat would you like to start with? A quick interests check (what you enjoy or want to learn), a specific task, or a playful activity? If you’re not sure, I can suggest a few options:\\n- Explain a concept you’re curious about in simple terms\\n- Help draft an email or document\\n- Plan a study or workout routine\\n- Brainstorm ideas for a project or story\\n- Tell you a joke or a fun fact\\n\\nTell me what you’re hoping for, and we’ll dive in.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.json()['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed4999e-207b-41c9-8d37-32166085f394",
   "metadata": {},
   "source": [
    "### Python LLM Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6609e22a-ca8c-41f1-ad14-e588d4385e6a",
   "metadata": {},
   "source": [
    "#### Using OpenAI model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "257b43fa-b3b5-4c1f-bc21-9ebeb06da9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2870b269-0728-4fbe-8025-d59e2fe03b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this by defaults detect the openai api key in environment variables\n",
    "# also detects the base url\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "62d0a820-9be5-41ce-80b6-ba59dc048ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nice to meet you too! I’m glad to be your AI buddy.\\n\\nI can chat, answer questions, brainstorm ideas, help with writing or coding, plan things, learn new topics, and play quick games. If you tell me your interests, I’ll tailor our chats.\\n\\nWhat would you like to do first? A quick Q&A, a brain-storm, a writing or coding task, a mini game, or something else?'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai.chat.completions.create(model='gpt-5-nano', messages=[{'role':'user', 'content': 'Hi, it is nice to meet my AI buddy'}])\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8805d3-9b8b-4b7f-a218-3e511c1bddcb",
   "metadata": {},
   "source": [
    "**Using Gooogle Gemini**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a0e2b247-b5e9-4396-b866-65f75950b8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to specify the gemini API key\n",
    "goog_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=goog_api_key ,\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "415bf17d-3694-4f7b-a111-51a1efd804e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(model='gemini-2.5-flash', messages=[{'role':'user', 'content': 'Hi, it is nice to meet my AI buddy'}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3d1eca1e-f39b-4cd1-a668-2e5154a23b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello there! It's great to meet you too!\n",
      "\n",
      "I'm ready and eager to assist you. What can I do for you today, or what would you like to chat about?\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891e12fd-75af-4a9c-a85e-d85d57445b76",
   "metadata": {},
   "source": [
    "**Using Ollama**\n",
    "\n",
    "ADVANTAGE\n",
    "* NO API charges (Open source).\n",
    "* Data is in your memory and secured.\n",
    "\n",
    "DISADVANTAGE\n",
    "* Less powerful compared to frontier models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5dd43a6b-cc85-4c88-92f3-454e2ea75bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'Ollama is running'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.get('http://localhost:11434').content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "665e0dac-0774-4e5b-9c28-3ed7c8796eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_base_url = 'http://localhost:11434/v1'\n",
    "\n",
    "ollama_client = OpenAI(\n",
    "    api_key='ollama',\n",
    "    base_url='http://localhost:11434/v1'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4962c976-b645-4eaf-a8e8-eac6d881e218",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = ollama_client.chat.completions.create(model='deepseek-r1:8b', messages=[{'role':'user', 'content': 'Hi, what is square root of 10'}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "421d157a-1b7e-4ee0-8b9d-5029a6d4d217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, the square root of 10 (written as √10) is approximately **3.1623**.\n",
      "\n",
      "It is an **irrational number**, which means it cannot be expressed exactly as a fraction and has a non-terminating, non-repeating decimal expansion.\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed2bc8b-dc0e-41ef-9b7d-cbfe725c914d",
   "metadata": {},
   "source": [
    "Using Markdown in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "923c1d7c-bc53-4594-a2a4-efa336f3059c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Okay, the square root of 10 (written as √10) is approximately **3.1623**.\n",
       "\n",
       "It is an **irrational number**, which means it cannot be expressed exactly as a fraction and has a non-terminating, non-repeating decimal expansion."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1833df30-c28b-40c5-87eb-345d2c8b2218",
   "metadata": {},
   "source": [
    "#### Using LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "949f486e-7a86-4e1b-b890-b5407883e339",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabri\\Documents\\Gabriel.O\\LLM Engineering\\simple_llm_app\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:26: UserWarning: Core Pydantic V1 functionality isn't compatible with Python 3.14 or greater.\n",
      "  from pydantic.v1.fields import FieldInfo as FieldInfoV1\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "656229fc-b774-46c5-b9d3-2a59c62a91d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_gemini = ChatOpenAI(openai_api_key=goog_api_key, model='gemini-2.5-flash', base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\")\n",
    "\n",
    "client_openai = ChatOpenAI(model='gpt-5-nano')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "999afd1c-885d-4142-acca-19cf39291ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client_gemini.invoke([{'role':'user', 'content': 'Hi, what is square root of 10'}])\n",
    "response_2 = client_openai.invoke([{'role':'user', 'content': 'Hi, what is square root of 10'}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ac55c267-5f25-41e1-bfb6-beb62f15da9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The square root of 10 is approximately **3.162**.\n",
       "\n",
       "It's an irrational number, which means its decimal representation goes on forever without repeating.\n",
       "\n",
       "You can verify this because:\n",
       "*   $3^2 = 9$\n",
       "*   $4^2 = 16$\n",
       "Since 10 is between 9 and 16, its square root is between 3 and 4."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "The square root of 10 is approximately 3.1622776601683795. It’s an irrational number. If you want it rounded, 3.1623 works (to four decimals)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response.content))\n",
    "display(Markdown(response_2.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9a562a-48d4-49e4-8a7b-9b5ec3558876",
   "metadata": {},
   "source": [
    "#### Using LightLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3c53888d-2352-425f-92f1-2bb53922c0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from litellm import completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0821f72d-ca48-406b-a732-00e5a93f4db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = [{'role':'user', 'content': 'Hi, what is square root of 10'}]\n",
    "response = completion(model=\"openai/gpt-5-nano\", messages=message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c8c03fb6-9254-47c3-a947-419a37522f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The square root of 10 is irrational and is approximately 3.1622776601683795.  \n",
       "If you want it rounded: about 3.1623 (to 4 decimals)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "787fe6e5-39d6-4d6f-879e-f1f8f7bd9fe2",
   "metadata": {},
   "source": [
    "Other Features of LiteLLM, to track token usage and cost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d112dfd2-4b7c-4744-a3b4-969fb90e8b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tokens: 15\n",
      "Output tokens: 305\n",
      "Total tokens: 320\n",
      "Total cost: 0.0123 cents\n"
     ]
    }
   ],
   "source": [
    "print(f\"Input tokens: {response.usage.prompt_tokens}\")\n",
    "print(f\"Output tokens: {response.usage.completion_tokens}\")\n",
    "print(f\"Total tokens: {response.usage.total_tokens}\")\n",
    "print(f\"Total cost: {response._hidden_params[\"response_cost\"]*100:.4f} cents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068ace31-41d3-4360-bbce-62b119b6d47d",
   "metadata": {},
   "source": [
    "### Chart Streaming in Gradio\n",
    "\n",
    "SItuation where chats is being read in real time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0a4cde6f-f4aa-4a5c-ae77-e62ad3690ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "db5cdbe8-162a-44b7-a602-a58018dbe928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7864\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def chat(message, history):\n",
    "    \"\"\"\n",
    "    Debugging what history is!\n",
    "    \"\"\"\n",
    "    history = [{\"role\":h[\"role\"], \"content\":h[\"content\"]} for h in history]\n",
    "    return f'{history + [{\"role\": \"user\", \"content\": message}]}\\n'\n",
    "\n",
    "\n",
    "gr.ChatInterface(fn=chat).launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "64df3e38-1964-40f1-88fc-f2c44a7fe25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are a helpful assistant in a clothes store. You should try to gently encourage \\\n",
    "the customer to try items that are on sale. Hats are 60% off, and most other items are 50% off. \\\n",
    "For example, if the customer says 'I'm looking to buy a hat', \\\n",
    "you could reply something like, 'Wonderful - we have lots of hats - including several that are part of our sales event.'\\\n",
    "Encourage the customer to buy hats if they are unsure what to get.\"\n",
    "\n",
    "system_message += \"\\nIf the customer asks for shoes, you should respond that shoes are not on sale today, \\\n",
    "but remind the customer to look at hats!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "803f2fcf-be55-4407-83bc-530708984a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL=\"gpt-5-nano\"\n",
    "def chat(message, history):\n",
    "    history = [{\"role\":h[\"role\"], \"content\":h[\"content\"]} for h in history]\n",
    "    relevant_system_message = system_message\n",
    "    if 'belt' in message.lower():\n",
    "        relevant_system_message += \" The store does not sell belts; if you are asked for belts, be sure to point out other items on sale.\"\n",
    "    \n",
    "    messages = [{\"role\": \"system\", \"content\": relevant_system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "\n",
    "    stream = openai.chat.completions.create(model=MODEL, messages=messages, stream=True)\n",
    "\n",
    "    response = \"\"\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        yield response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "827f035f-a332-4ef9-a7a9-b07ea1c21c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7865\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7865/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(fn=chat).launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f446d2a-25d1-4489-a141-39593e186b3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba5f386-0099-4b82-ac03-96e98979ddab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
